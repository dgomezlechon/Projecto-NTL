{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79813218",
   "metadata": {},
   "source": [
    "# Extracción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eb72a",
   "metadata": {},
   "source": [
    "## Método 1: CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caaa511",
   "metadata": {},
   "source": [
    "Primero vamos a extraer los csv con los datos históricos de los precios en bolsa de Apple, Samsung, Twitter y Microsoft desde el 1 de enero de 2015. He sacado los csv de yahoo finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae59c5",
   "metadata": {},
   "source": [
    "Importamos librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95166eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# para pintar\n",
    "#import pylab as plt\n",
    "#import seaborn as sns\n",
    "#import numpy as np\n",
    "\n",
    "# para que salga el grafico\n",
    "#%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f1a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_price=pd.read_csv(\"../data/AAPL.csv\")\n",
    "microsoft_price=pd.read_csv(\"../data/MSFT.csv\")\n",
    "twitter_price=pd.read_csv(\"../data/TWTR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1274f6d3",
   "metadata": {},
   "source": [
    "Compruebo que no hayan nulos ni duplicados con i.e twitter_csv.duplicated().any() y i.e apple_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6b31a",
   "metadata": {},
   "source": [
    "## Método 2:  Web Scraping (selenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3344a",
   "metadata": {},
   "source": [
    "Vamos a escrapear la página \"Alpha Query\" para obtener el EPS histórico de las empresas, tanto los estimates como loas actuales y las fechas de publicación "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0b38d",
   "metadata": {},
   "source": [
    "Importamos librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2abd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae21ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35ee194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Driver [/Users/danigomezlechonbarrachina/.wdm/drivers/chromedriver/mac64/100.0.4896.60/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "from apifunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33bad0",
   "metadata": {},
   "source": [
    "Definimos las URL que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19000e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=[\"AAPL\",\"MSFT\",\"TWTR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705abaa8",
   "metadata": {},
   "source": [
    "Sacamos los datos para todas las empresas de la lista tickers utilizando la función \"earnings\" que está en el archivo 'apifunctions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d88488",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablita = earnings(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d07d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_earnings=tablita[0]\n",
    "microsoft_earnings=tablita[1]\n",
    "twitter_earnings=tablita[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2ff3d",
   "metadata": {},
   "source": [
    "Comprobamos que no hayan nulos ni duplicados como hemos hecho con los csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089f78f",
   "metadata": {},
   "source": [
    "Guardo las dataframes para poder usarlas en el archivo de transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee10328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'apple_earnings' (DataFrame)\n",
      "Stored 'microsoft_earnings' (DataFrame)\n",
      "Stored 'twitter_earnings' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store apple_price\n",
    "%store microsoft_price\n",
    "%store twitter_price\n",
    "%store apple_earnings\n",
    "%store microsoft_earnings\n",
    "%store twitter_earnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f474c",
   "metadata": {},
   "source": [
    "## Método 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e764e4f",
   "metadata": {},
   "source": [
    "Ahora queremos sacar para cada una de las empresas y cada uno de los días cual fue la noticia principal ese día, \n",
    "de esta manera podemos ver cual es la razón por la que la acción puede tener cierto movimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfb2f2",
   "metadata": {},
   "source": [
    "Para ello he definido la función get_news_link que nos para una acción concreta en una fecha dada, el link a la primera noticia de google'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
